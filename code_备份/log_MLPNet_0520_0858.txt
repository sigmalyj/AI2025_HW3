------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.553s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 19800
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 1 in 23.395s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.529s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 39600
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win14, lose4, draw2
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win4, lose4, draw2
------ Finished Self-Play Iteration 2 in 33.266s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.516s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 59400
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 3 in 19.873s ------

------ Start Self-Play Iteration 4 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.506s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 79200
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win0, draw10; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win14, lose3, draw3
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win5, lose2, draw3
------ Finished Self-Play Iteration 4 in 29.112s ------

------ Start Self-Play Iteration 5 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.613s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 5 in 27.936s ------

------ Start Self-Play Iteration 6 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.697s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win18, lose2, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 6 in 28.200s ------

------ Start Self-Play Iteration 7 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.668s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 7 in 21.018s ------

------ Start Self-Play Iteration 8 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.602s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 8 in 22.038s ------

------ Start Self-Play Iteration 9 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.624s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win10, draw10; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 9 in 20.903s ------

------ Start Self-Play Iteration 10 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.530s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 10 in 20.470s ------

------ Start Self-Play Iteration 11 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.727s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win0, draw10; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win16, lose2, draw2
[EVALUATION RESULT]:(first)  win8, lose0, draw2
[EVALUATION RESULT]:(second) win8, lose2, draw0
------ Finished Self-Play Iteration 11 in 29.754s ------

------ Start Self-Play Iteration 12 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.556s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 12 in 20.533s ------

------ Start Self-Play Iteration 13 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.542s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 13 in 24.251s ------

------ Start Self-Play Iteration 14 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.538s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 14 in 20.724s ------

------ Start Self-Play Iteration 15 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.583s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 15 in 20.992s ------

------ Start Self-Play Iteration 16 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.662s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win0, draw10; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose3, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win8, lose2, draw0
------ Finished Self-Play Iteration 16 in 28.220s ------

------ Start Self-Play Iteration 17 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.590s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 17 in 22.134s ------

------ Start Self-Play Iteration 18 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.652s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win10, draw10; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 18 in 19.940s ------

------ Start Self-Play Iteration 19 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.546s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win0, draw20; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win14, lose1, draw5
[EVALUATION RESULT]:(first)  win6, lose0, draw4
[EVALUATION RESULT]:(second) win8, lose1, draw1
------ Finished Self-Play Iteration 19 in 28.237s ------

------ Start Self-Play Iteration 20 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.539s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 20 in 30.095s ------

------ Start Self-Play Iteration 21 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.538s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win0, draw10; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win14, lose5, draw1
[EVALUATION RESULT]:(first)  win7, lose2, draw1
[EVALUATION RESULT]:(second) win7, lose3, draw0
------ Finished Self-Play Iteration 21 in 28.674s ------

------ Start Self-Play Iteration 22 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.534s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win10, draw10; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 22 in 20.712s ------

------ Start Self-Play Iteration 23 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.659s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 23 in 19.318s ------

------ Start Self-Play Iteration 24 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.820s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 24 in 22.297s ------

------ Start Self-Play Iteration 25 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.586s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 25 in 22.450s ------

------ Start Self-Play Iteration 26 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.549s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win10, draw10; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 26 in 24.792s ------

------ Start Self-Play Iteration 27 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.541s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 27 in 21.400s ------

------ Start Self-Play Iteration 28 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.907s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win0, draw10; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win14, lose5, draw1
[EVALUATION RESULT]:(first)  win8, lose2, draw0
[EVALUATION RESULT]:(second) win6, lose3, draw1
------ Finished Self-Play Iteration 28 in 27.776s ------

------ Start Self-Play Iteration 29 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.586s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win0, draw10; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win14, lose3, draw3
[EVALUATION RESULT]:(first)  win7, lose1, draw2
[EVALUATION RESULT]:(second) win7, lose2, draw1
------ Finished Self-Play Iteration 29 in 28.516s ------

------ Start Self-Play Iteration 30 ------
[AlphaZeroParallel] Finished 20 episodes (19800 examples) in 0.543s, Win: 0, Draw: 0, Lose: 20
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 30 in 23.977s ------

[round_robin] All done.
